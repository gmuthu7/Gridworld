{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "<h1> Advantage Actor Critic on continuous actions </h1>\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "13f55af02d21206a"
  },
  {
   "cell_type": "markdown",
   "source": [
    "<h3> Import dependencies </h3>"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "e745491f8f1a5f6a"
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2023-09-21T12:36:48.259196Z",
     "start_time": "2023-09-21T12:36:43.755057Z"
    }
   },
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[1], line 7\u001B[0m\n\u001B[1;32m      5\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mmatplotlib\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01maxes\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m Axes\n\u001B[1;32m      6\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mmatplotlib\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mfigure\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m Figure\n\u001B[0;32m----> 7\u001B[0m \u001B[38;5;28;01mimport\u001B[39;00m \u001B[38;5;21;01mtorch\u001B[39;00m\n\u001B[1;32m      8\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mtorch\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m nn\n\u001B[1;32m      9\u001B[0m \u001B[38;5;28;01mimport\u001B[39;00m \u001B[38;5;21;01mcloudpickle\u001B[39;00m\n",
      "File \u001B[0;32m_pydevd_bundle/pydevd_cython_darwin_311_64.pyx:1179\u001B[0m, in \u001B[0;36m_pydevd_bundle.pydevd_cython_darwin_311_64.SafeCallWrapper.__call__\u001B[0;34m()\u001B[0m\n",
      "File \u001B[0;32m_pydevd_bundle/pydevd_cython_darwin_311_64.pyx:620\u001B[0m, in \u001B[0;36m_pydevd_bundle.pydevd_cython_darwin_311_64.PyDBFrame.trace_dispatch\u001B[0;34m()\u001B[0m\n",
      "File \u001B[0;32m_pydevd_bundle/pydevd_cython_darwin_311_64.pyx:1095\u001B[0m, in \u001B[0;36m_pydevd_bundle.pydevd_cython_darwin_311_64.PyDBFrame.trace_dispatch\u001B[0;34m()\u001B[0m\n",
      "File \u001B[0;32m_pydevd_bundle/pydevd_cython_darwin_311_64.pyx:1053\u001B[0m, in \u001B[0;36m_pydevd_bundle.pydevd_cython_darwin_311_64.PyDBFrame.trace_dispatch\u001B[0;34m()\u001B[0m\n",
      "File \u001B[0;32m/Applications/PyCharm.app/Contents/plugins/python/helpers-pro/jupyter_debug/pydev_jupyter_plugin.py:169\u001B[0m, in \u001B[0;36mstop\u001B[0;34m(plugin, pydb, frame, event, args, stop_info, arg, step_cmd)\u001B[0m\n\u001B[1;32m    167\u001B[0m     frame \u001B[38;5;241m=\u001B[39m suspend_jupyter(main_debugger, thread, frame, step_cmd)\n\u001B[1;32m    168\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m frame:\n\u001B[0;32m--> 169\u001B[0m         \u001B[43mmain_debugger\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mdo_wait_suspend\u001B[49m\u001B[43m(\u001B[49m\u001B[43mthread\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mframe\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mevent\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43marg\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    170\u001B[0m         \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;01mTrue\u001B[39;00m\n\u001B[1;32m    171\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;01mFalse\u001B[39;00m\n",
      "File \u001B[0;32m/Applications/PyCharm.app/Contents/plugins/python/helpers/pydev/pydevd.py:1160\u001B[0m, in \u001B[0;36mPyDB.do_wait_suspend\u001B[0;34m(self, thread, frame, event, arg, send_suspend_message, is_unhandled_exception)\u001B[0m\n\u001B[1;32m   1157\u001B[0m         from_this_thread\u001B[38;5;241m.\u001B[39mappend(frame_id)\n\u001B[1;32m   1159\u001B[0m \u001B[38;5;28;01mwith\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_threads_suspended_single_notification\u001B[38;5;241m.\u001B[39mnotify_thread_suspended(thread_id, stop_reason):\n\u001B[0;32m-> 1160\u001B[0m     \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_do_wait_suspend\u001B[49m\u001B[43m(\u001B[49m\u001B[43mthread\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mframe\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mevent\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43marg\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43msuspend_type\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mfrom_this_thread\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m/Applications/PyCharm.app/Contents/plugins/python/helpers/pydev/pydevd.py:1175\u001B[0m, in \u001B[0;36mPyDB._do_wait_suspend\u001B[0;34m(self, thread, frame, event, arg, suspend_type, from_this_thread)\u001B[0m\n\u001B[1;32m   1172\u001B[0m             \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_call_mpl_hook()\n\u001B[1;32m   1174\u001B[0m         \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mprocess_internal_commands()\n\u001B[0;32m-> 1175\u001B[0m         \u001B[43mtime\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43msleep\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m0.01\u001B[39;49m\u001B[43m)\u001B[49m\n\u001B[1;32m   1177\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mcancel_async_evaluation(get_current_thread_id(thread), \u001B[38;5;28mstr\u001B[39m(\u001B[38;5;28mid\u001B[39m(frame)))\n\u001B[1;32m   1179\u001B[0m \u001B[38;5;66;03m# process any stepping instructions\u001B[39;00m\n",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import gymnasium\n",
    "from tqdm import tqdm\n",
    "from matplotlib.axes import Axes\n",
    "from matplotlib.figure import Figure\n",
    "import torch\n",
    "from torch import nn\n",
    "import cloudpickle\n",
    "import sklearn\n",
    "from sklearn import preprocessing\n",
    "torch.set_grad_enabled(True) "
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "<h3> Helper functions </h3>"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "3f5d4c5608659f00"
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "def get_grads(model:torch.nn.Module):\n",
    "    g = [param.grad.flatten() for param in model.parameters() if param.grad is not None]\n",
    "    g = torch.cat(g).norm()\n",
    "    return g"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-09-21T12:32:45.854930Z",
     "start_time": "2023-09-21T12:32:45.820751Z"
    }
   },
   "id": "3fcd9d82bbfb36c7"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def dump():\n",
    "    with (open(\"./models/actor.pkl\",\"wb\") as f1, \n",
    "          open(\"./models/critic.pkl\",\"wb\") as f2, \n",
    "          open(\"./models/scaler.pkl\",\"wb\") as f3):\n",
    "        cloudpickle.dump(actor,f1)\n",
    "        cloudpickle.dump(critic,f2)\n",
    "        cloudpickle.dump(scaler,f3)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "a4557cabafea6326"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def load():\n",
    "    with (open(\"./models/actor.pkl\",\"rb\") as f1, \n",
    "          open(\"./models/critic.pkl\",\"rb\") as f2, \n",
    "          open(\"./models/scaler.pkl\",\"rb\") as f3):\n",
    "        actor = cloudpickle.load(f1)\n",
    "        critic = cloudpickle.load(f2)\n",
    "        scaler = cloudpickle.load(f3)\n",
    "        return actor,critic,scaler"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "857a38406a5206c0"
  },
  {
   "cell_type": "markdown",
   "source": [
    "<h3> Actor critic helper classes </h3>"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "20c5eaa5251e8b7b"
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "class Actor:\n",
    "    def __init__(self):\n",
    "        self.pi = nn.Sequential(nn.Linear(2,50),\n",
    "                  nn.ReLU(),\n",
    "                  nn.Linear(50,2))\n",
    "        \n",
    "    def log_prob(self,state,action):\n",
    "        dist =self._get_dist(state)\n",
    "        return dist.log_prob(action),dist.entropy()\n",
    "    \n",
    "    def sample(self,state):\n",
    "        dist =self._get_dist(state)\n",
    "        _sample = dist.sample((1,))\n",
    "        return _sample\n",
    "    \n",
    "    def _get_dist(self,state):\n",
    "        mu,sigma = self.pi(state)\n",
    "        sigma = torch.nn.Softplus()(sigma) + 1e-1\n",
    "        dist = torch.distributions.Normal(mu,sigma)\n",
    "        return dist"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-09-21T12:32:45.862015Z",
     "start_time": "2023-09-21T12:32:45.824893Z"
    }
   },
   "id": "748dcd157f21d3d6"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "class Critic:\n",
    "    def __init__(self):\n",
    "        self.v = nn.Sequential(nn.Linear(2,100),\n",
    "                  nn.ReLU(),\n",
    "                  nn.Linear(100,1))\n",
    "    \n",
    "    def val(self,state):\n",
    "        _val = self.v(state)\n",
    "        return _val\n",
    "    "
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "1cd6bbbaae5da9fa"
  },
  {
   "cell_type": "markdown",
   "source": [
    "<h3> Implementation of A2C </h3>"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "f90f23ad56de23c4"
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[5], line 37\u001B[0m\n\u001B[1;32m     35\u001B[0m updates\u001B[38;5;241m+\u001B[39m\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m1\u001B[39m\n\u001B[1;32m     36\u001B[0m rewards\u001B[38;5;241m.\u001B[39mappend(reward)\n\u001B[0;32m---> 37\u001B[0m reward\u001B[38;5;241m-\u001B[39m\u001B[38;5;241m=\u001B[39m \u001B[43mnp\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mmean\u001B[49m\u001B[43m(\u001B[49m\u001B[43mrewards\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m     38\u001B[0m reward\u001B[38;5;241m/\u001B[39m\u001B[38;5;241m=\u001B[39m (np\u001B[38;5;241m.\u001B[39mstd(rewards)\u001B[38;5;241m+\u001B[39m\u001B[38;5;241m1e-3\u001B[39m)\n\u001B[1;32m     39\u001B[0m next_state \u001B[38;5;241m=\u001B[39m np\u001B[38;5;241m.\u001B[39msqueeze(scaler\u001B[38;5;241m.\u001B[39mtransform([next_state]))\n",
      "File \u001B[0;32m~/Library/Caches/pypoetry/virtualenvs/gridworld-1-zk00QJ-py3.11/lib/python3.11/site-packages/numpy/core/fromnumeric.py:3504\u001B[0m, in \u001B[0;36mmean\u001B[0;34m(a, axis, dtype, out, keepdims, where)\u001B[0m\n\u001B[1;32m   3501\u001B[0m     \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m   3502\u001B[0m         \u001B[38;5;28;01mreturn\u001B[39;00m mean(axis\u001B[38;5;241m=\u001B[39maxis, dtype\u001B[38;5;241m=\u001B[39mdtype, out\u001B[38;5;241m=\u001B[39mout, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n\u001B[0;32m-> 3504\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43m_methods\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_mean\u001B[49m\u001B[43m(\u001B[49m\u001B[43ma\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43maxis\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43maxis\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mdtype\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mdtype\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   3505\u001B[0m \u001B[43m                      \u001B[49m\u001B[43mout\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mout\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/Library/Caches/pypoetry/virtualenvs/gridworld-1-zk00QJ-py3.11/lib/python3.11/site-packages/numpy/core/_methods.py:102\u001B[0m, in \u001B[0;36m_mean\u001B[0;34m(a, axis, dtype, out, keepdims, where)\u001B[0m\n\u001B[1;32m    101\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21m_mean\u001B[39m(a, axis\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mNone\u001B[39;00m, dtype\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mNone\u001B[39;00m, out\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mNone\u001B[39;00m, keepdims\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mFalse\u001B[39;00m, \u001B[38;5;241m*\u001B[39m, where\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mTrue\u001B[39;00m):\n\u001B[0;32m--> 102\u001B[0m     arr \u001B[38;5;241m=\u001B[39m asanyarray(a)\n\u001B[1;32m    104\u001B[0m     is_float16_result \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mFalse\u001B[39;00m\n\u001B[1;32m    106\u001B[0m     rcount \u001B[38;5;241m=\u001B[39m _count_reduce_items(arr, axis, keepdims\u001B[38;5;241m=\u001B[39mkeepdims, where\u001B[38;5;241m=\u001B[39mwhere)\n",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "source": [
    "NUM_TRIALS = 1\n",
    "NUM_EPISODES = 1000\n",
    "ALPHA_V = 1e-3\n",
    "ALPHA_PI = 1e-4\n",
    "GAMMA = 1\n",
    "update_critic = True\n",
    "updates = 0\n",
    "mse_loss = nn.MSELoss()\n",
    "actor = Actor()\n",
    "critic = Critic()\n",
    "pi_op = torch.optim.AdamW(actor.pi.parameters(),lr=ALPHA_PI)\n",
    "v_op = torch.optim.AdamW(critic.v.parameters(),lr=ALPHA_V)\n",
    "env = gymnasium.make(\"MountainCarContinuous-v0\")\n",
    "scaler = sklearn.preprocessing.StandardScaler()\n",
    "returns = []\n",
    "ep_lens = []\n",
    "grads = [[],[]]\n",
    "losses = [[],[]]\n",
    "entropies = []\n",
    "rewards = []\n",
    "scaler.fit(np.array([env.observation_space.sample() for _ in range(10000)]))\n",
    "for j in range(NUM_EPISODES):\n",
    "    ret = 0.\n",
    "    ep_len=0.\n",
    "    state,*_ = env.reset()\n",
    "    state = np.squeeze(scaler.transform([state]))\n",
    "    state = torch.as_tensor(state).float()\n",
    "    while True:\n",
    "        with torch.no_grad():\n",
    "            action = actor.sample(state)\n",
    "            action = torch.clamp(action,env.action_space.low[0],env.action_space.high[0])\n",
    "        next_state,reward,terminated,truncated,*_ = env.step(action)\n",
    "        ret+=reward\n",
    "        ep_len+=1\n",
    "        updates+=1\n",
    "        rewards.append(reward)\n",
    "        reward-= np.mean(rewards)\n",
    "        reward/= (np.std(rewards)+1e-3)\n",
    "        next_state = np.squeeze(scaler.transform([next_state]))\n",
    "        next_state = torch.as_tensor(next_state).float()\n",
    "        if updates%5 == 0:\n",
    "            update_critic = not update_critic\n",
    "        if update_critic:\n",
    "            with torch.no_grad():\n",
    "                target = torch.tensor([reward],dtype=torch.float) + GAMMA * (critic.val(next_state) if not terminated else 0)\n",
    "            v_op.zero_grad()\n",
    "            est_v = critic.val(state)\n",
    "            loss = mse_loss(target,est_v)\n",
    "            loss.backward()\n",
    "            v_op.step()\n",
    "            with torch.no_grad():\n",
    "                losses[0].append(loss.item())\n",
    "                grads[0].append(get_grads(critic.v))\n",
    "        else:\n",
    "            with torch.no_grad():\n",
    "                critic_est = torch.tensor([reward],dtype=torch.float) + GAMMA*(critic.val(next_state) if not terminated else 0) - critic.val(state)\n",
    "            pi_op.zero_grad()\n",
    "            prob = actor.log_prob(state,action)\n",
    "            loss = critic_est*prob[0]*-1 \n",
    "            loss.backward()\n",
    "            pi_op.step()\n",
    "            with torch.no_grad():\n",
    "                losses[1].append(loss.item())\n",
    "                grads[1].append(get_grads(actor.pi))\n",
    "                entropies.append(prob[1].numpy())\n",
    "        state = next_state\n",
    "        if terminated or truncated:\n",
    "            if terminated:\n",
    "                print(\"Achieved target in\",ep_len,\"steps at ep\",j,\"with ret\",ret)\n",
    "            break\n",
    "    returns.append(ret)\n",
    "    ep_lens.append(ep_len)\n",
    "        "
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-09-21T12:33:16.744472Z",
     "start_time": "2023-09-21T12:32:45.831615Z"
    }
   },
   "id": "c0f9081d0cf83eb7"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "fig:Figure\n",
    "ax1:Axes\n",
    "ax2:Axes\n",
    "ax3:Axes\n",
    "ax4:Axes\n",
    "ax5:Axes\n",
    "ax6:Axes\n",
    "fig,((ax1,ax2),(ax3,ax4),(ax5,ax6),(ax7,ax8)) = plt.subplots(4,2)\n",
    "fig.set_figwidth(20)\n",
    "fig.set_figheight(20)\n",
    "fig.tight_layout(pad=5.0)\n",
    "ax1.plot(returns[:j])\n",
    "ax1.set_ylabel(f\"Mean return {NUM_TRIALS} trials\")\n",
    "ax1.set_xlabel(\"Episode\")\n",
    "ax1.set_title(\"Mean Return\")\n",
    "ax2.plot(ep_lens[:j])\n",
    "ax2.set_ylabel(f\"Mean episode length {NUM_TRIALS} trials\")\n",
    "ax2.set_xlabel(\"Episode\")\n",
    "ax2.set_title(\"Mean Episode Length\")\n",
    "ax3.plot(grads[0])\n",
    "ax3.set_ylabel(f\"Grad Norm\")\n",
    "ax3.set_xlabel(\"Grad Index\")\n",
    "ax3.set_title(\"Critic Grad Norm\")\n",
    "ax4.plot(losses[0])\n",
    "ax4.set_ylabel(f\"Loss\")\n",
    "ax4.set_xlabel(\"Loss Index\")\n",
    "ax4.set_title(\"Critic Loss\")\n",
    "ax5.plot(grads[1])\n",
    "ax5.set_ylabel(f\"Grad Norm\")\n",
    "ax5.set_xlabel(\"Grad Index\")\n",
    "ax5.set_title(\"Actor Grad Norm\")\n",
    "ax6.plot(losses[1])\n",
    "ax6.set_ylabel(f\"Loss\")\n",
    "ax6.set_xlabel(\"Loss Index\")\n",
    "ax6.set_title(\"Actor Loss\");\n",
    "ax7.plot(entropies)\n",
    "ax7.set_ylabel(f\"Entropy\")\n",
    "ax7.set_xlabel(\"Index\")\n",
    "ax7.set_title(\"Entropy Loss\");\n",
    "ax8.plot(rewards)\n",
    "ax8.set_ylabel(f\"Rewards\")\n",
    "ax8.set_xlabel(\"Index\")\n",
    "ax8.set_title(\"Rewards\");"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-09-21T12:33:16.745383Z"
    }
   },
   "id": "8ec3163f43658331"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "list(critic.v.parameters())[0]"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-09-21T12:33:16.748261Z",
     "start_time": "2023-09-21T12:33:16.746361Z"
    }
   },
   "id": "98d6247f212435cf"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "list(actor.pi.parameters())[0]"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-09-21T12:33:16.747764Z"
    }
   },
   "id": "8642abe359a34b8d"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "returns[:,:j]"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-09-21T12:33:16.749023Z"
    }
   },
   "id": "90ea1a4b45b3efb0"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "dump()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-09-21T12:33:16.750143Z"
    }
   },
   "id": "12514dda01e24ddf"
  },
  {
   "cell_type": "markdown",
   "source": [
    "<h3> Evaluate in human render mode </h3>"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "1b39d92e97101cb3"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "actor,critic,scaler = load()\n",
    "env = gymnasium.make(\"MountainCarContinuous-v0\",render_mode=\"human\")\n",
    "for _ in range(10):\n",
    "    state,*_ = env.reset()\n",
    "    while True:\n",
    "        state = np.squeeze(scaler.transform([state]))\n",
    "        state = torch.from_numpy(state).detach().float()\n",
    "        with torch.no_grad():\n",
    "            action = actor.sample(state)\n",
    "        next_state,reward,terminated,truncated,*_ = env.step(action)\n",
    "        if terminated or terminated:\n",
    "            break\n",
    "        state = next_state"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-09-21T12:33:16.751098Z"
    }
   },
   "id": "5c9a68065b248880"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-09-21T12:33:16.751689Z"
    }
   },
   "id": "4e300aaf2ed574e5"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
