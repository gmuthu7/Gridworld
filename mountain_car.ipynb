{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "<h1> Advantage Actor Critic on continuous actions </h1>\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "13f55af02d21206a"
  },
  {
   "cell_type": "markdown",
   "source": [
    "<h3> Import dependencies </h3>"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "e745491f8f1a5f6a"
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2023-09-18T07:22:27.442740Z",
     "start_time": "2023-09-18T07:22:27.392266Z"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import gymnasium\n",
    "from tqdm import tqdm\n",
    "from matplotlib.axes import Axes\n",
    "from matplotlib.figure import Figure\n",
    "import torch\n",
    "from torch import nn\n",
    "import cloudpickle\n",
    "import sklearn\n",
    "from sklearn import preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "<h3> Helper functions </h3>"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "3f5d4c5608659f00"
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [],
   "source": [
    "def get_grads(model:torch.nn.Module):\n",
    "    g = [param.grad.detach().flatten() for param in model.parameters() if param.grad is not None]\n",
    "    g = torch.cat(g).norm()\n",
    "    return g\n",
    "def dump():\n",
    "    with (open(\"./models/actor.pkl\",\"wb\") as f1, \n",
    "          open(\"./models/critic.pkl\",\"wb\") as f2, \n",
    "          open(\"./models/scaler.pkl\",\"wb\") as f3):\n",
    "        cloudpickle.dump(actor,f1)\n",
    "        cloudpickle.dump(critic,f2)\n",
    "        cloudpickle.dump(scaler,f3)\n",
    "def load():\n",
    "    with (open(\"./models/actor.pkl\",\"rb\") as f1, \n",
    "          open(\"./models/critic.pkl\",\"rb\") as f2, \n",
    "          open(\"./models/scaler.pkl\",\"rb\") as f3):\n",
    "        actor = cloudpickle.load(f1)\n",
    "        critic = cloudpickle.load(f2)\n",
    "        scaler = cloudpickle.load(f3)\n",
    "        return actor,critic,scaler"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-09-18T07:22:28.548093Z",
     "start_time": "2023-09-18T07:22:28.545206Z"
    }
   },
   "id": "3fcd9d82bbfb36c7"
  },
  {
   "cell_type": "markdown",
   "source": [
    "<h3> Actor critic helper classes </h3>"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "20c5eaa5251e8b7b"
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [],
   "source": [
    "class Actor:\n",
    "    def __init__(self):\n",
    "        self.pi = nn.Sequential(nn.Linear(2,50),\n",
    "                  nn.ReLU(),\n",
    "                  nn.Linear(50,2))\n",
    "    def log_prob(self,state,action):\n",
    "        dist =self._get_dist(state)\n",
    "        return dist.log_prob(action)\n",
    "    \n",
    "    def sample(self,state):\n",
    "        dist =self._get_dist(state)\n",
    "        _sample = dist.sample((1,))\n",
    "        if np.isnan(_sample):\n",
    "            raise Exception(\"Action is nan\")\n",
    "    \n",
    "    def _get_dist(self,state):\n",
    "        mu,sigma = self.pi(state)\n",
    "        sigma = torch.nn.Softplus()(sigma)\n",
    "        dist = torch.distributions.Normal(mu,sigma+1e-5)\n",
    "        return dist\n",
    "\n",
    "class Critic:\n",
    "    def __init(self):\n",
    "        self.v = nn.Sequential(nn.Linear(2,100),\n",
    "                  nn.ReLU(),\n",
    "                  nn.Linear(100,1))\n",
    "    \n",
    "    def val(self,state):\n",
    "        _val = self.v(state)\n",
    "        return _val\n",
    "    "
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-09-18T07:22:29.409138Z",
     "start_time": "2023-09-18T07:22:29.405466Z"
    }
   },
   "id": "748dcd157f21d3d6"
  },
  {
   "cell_type": "markdown",
   "source": [
    "<h3> Implementation of A2C </h3>"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "f90f23ad56de23c4"
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'Critic' object has no attribute 'v'",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mAttributeError\u001B[0m                            Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[10], line 17\u001B[0m\n\u001B[1;32m     15\u001B[0m mse_loss \u001B[38;5;241m=\u001B[39m nn\u001B[38;5;241m.\u001B[39mMSELoss()\n\u001B[1;32m     16\u001B[0m pi_op \u001B[38;5;241m=\u001B[39m torch\u001B[38;5;241m.\u001B[39moptim\u001B[38;5;241m.\u001B[39mSGD(actor\u001B[38;5;241m.\u001B[39mpi\u001B[38;5;241m.\u001B[39mparameters(),lr\u001B[38;5;241m=\u001B[39mALPHA_PI)\n\u001B[0;32m---> 17\u001B[0m v_op \u001B[38;5;241m=\u001B[39m torch\u001B[38;5;241m.\u001B[39moptim\u001B[38;5;241m.\u001B[39mSGD(\u001B[43mcritic\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mv\u001B[49m\u001B[38;5;241m.\u001B[39mparameters(),lr\u001B[38;5;241m=\u001B[39mALPHA_V)\n\u001B[1;32m     18\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m j \u001B[38;5;129;01min\u001B[39;00m tqdm(\u001B[38;5;28mrange\u001B[39m(NUM_EPISODES)):\n\u001B[1;32m     19\u001B[0m     ret \u001B[38;5;241m=\u001B[39m \u001B[38;5;241m0.\u001B[39m\n",
      "\u001B[0;31mAttributeError\u001B[0m: 'Critic' object has no attribute 'v'"
     ]
    }
   ],
   "source": [
    "NUM_TRIALS = 1\n",
    "NUM_EPISODES = 1000\n",
    "ALPHA_V = 56e-5\n",
    "ALPHA_PI = 1e-5\n",
    "env = gymnasium.make(\"MountainCarContinuous-v0\")\n",
    "returns = np.zeros((NUM_TRIALS,NUM_EPISODES))\n",
    "ep_lens = np.zeros((NUM_TRIALS,NUM_EPISODES))\n",
    "grads = [[],[]]\n",
    "losses = [[],[]]\n",
    "for i in range(NUM_TRIALS):\n",
    "    actor = Actor()\n",
    "    critic = Critic()\n",
    "    scaler = sklearn.preprocessing.StandardScaler()\n",
    "    scaler.fit(np.array([env.observation_space.sample() for _ in range(10000)]))\n",
    "    mse_loss = nn.MSELoss()\n",
    "    pi_op = torch.optim.SGD(actor.pi.parameters(),lr=ALPHA_PI)\n",
    "    v_op = torch.optim.SGD(critic.v.parameters(),lr=ALPHA_V)\n",
    "    for j in tqdm(range(NUM_EPISODES)):\n",
    "        ret = 0.\n",
    "        ep_len=0.\n",
    "        state,*_ = env.reset()\n",
    "        state = np.squeeze(scaler.transform([state]))\n",
    "        state = torch.from_numpy(state).detach().float()\n",
    "        while True:\n",
    "            with torch.no_grad():\n",
    "                action = actor.sample(state)\n",
    "            next_state,reward,terminated,truncated,*_ = env.step(action)\n",
    "            next_state = np.squeeze(scaler.transform([next_state]))\n",
    "            next_state = torch.from_numpy(next_state).detach().float()\n",
    "            with torch.no_grad():\n",
    "                target = torch.tensor([reward]) + (critic.val(next_state) if not terminated else 0)\n",
    "            v_op.zero_grad()\n",
    "            est_v = critic.val(state)\n",
    "            loss = mse_loss(target,est_v)\n",
    "            loss.backward()\n",
    "            v_op.step()\n",
    "            losses[0].append(loss.detach().item())\n",
    "            grads[0].append(get_grads(critic.v))\n",
    "            with torch.no_grad():\n",
    "                critic_est = torch.tensor([reward]) + (critic.val(next_state) if not terminated else 0) - critic.val(state)\n",
    "            pi_op.zero_grad()\n",
    "            prob = actor.log_prob(state,action)\n",
    "            loss = critic_est*prob*-1 #The -1 is needed coz pytorch always does SGD and not ascent\n",
    "            loss.backward()\n",
    "            pi_op.step()\n",
    "            losses[1].append(loss.detach().item())\n",
    "            grads[1].append(get_grads(actor.pi))\n",
    "            state = next_state\n",
    "            ret+=reward\n",
    "            ep_len+=1\n",
    "            if terminated or truncated:\n",
    "                if terminated:\n",
    "                    print(\"Achieved target in \",ep_len)\n",
    "                break\n",
    "        returns[i,j] = ret\n",
    "        ep_lens[i,j] = ep_len\n",
    "        "
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-09-18T07:22:30.503854Z",
     "start_time": "2023-09-18T07:22:30.352145Z"
    }
   },
   "id": "c0f9081d0cf83eb7"
  },
  {
   "cell_type": "markdown",
   "source": [
    "<h3> Plot metrics </h3>"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "6b36b9e2f06416f3"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "fig:Figure\n",
    "ax1:Axes\n",
    "ax2:Axes\n",
    "ax3:Axes\n",
    "ax4:Axes\n",
    "ax5:Axes\n",
    "ax6:Axes\n",
    "fig,((ax1,ax2),(ax3,ax4),(ax5,ax6)) = plt.subplots(3,2)\n",
    "fig.set_figwidth(20)\n",
    "fig.set_figheight(20)\n",
    "fig.tight_layout(pad=5.0)\n",
    "ax1.plot(np.mean(returns[:][:j],axis=0))\n",
    "ax1.set_ylabel(f\"Mean return {NUM_TRIALS} trials\")\n",
    "ax1.set_xlabel(\"Episode\")\n",
    "ax1.set_title(\"Mean Return\")\n",
    "ax2.plot(np.mean(ep_lens[:][:j],axis=0))\n",
    "ax2.set_ylabel(f\"Mean episode length {NUM_TRIALS} trials\")\n",
    "ax2.set_xlabel(\"Episode\")\n",
    "ax2.set_title(\"Mean Episode Length\")\n",
    "ax3.plot(grads[0])\n",
    "ax3.set_ylabel(f\"Grad Norm\")\n",
    "ax3.set_xlabel(\"Grad Index\")\n",
    "ax3.set_title(\"Critic Grad Norm\")\n",
    "ax4.plot(losses[0])\n",
    "ax4.set_ylabel(f\"Loss\")\n",
    "ax4.set_xlabel(\"Loss Index\")\n",
    "ax4.set_title(\"Critic Loss\")\n",
    "ax5.plot(grads[1])\n",
    "ax5.set_ylabel(f\"Grad Norm\")\n",
    "ax5.set_xlabel(\"Grad Index\")\n",
    "ax5.set_title(\"Actor Grad Norm\")\n",
    "ax6.plot(losses[1])\n",
    "ax6.set_ylabel(f\"Loss\")\n",
    "ax6.set_xlabel(\"Loss Index\")\n",
    "ax6.set_title(\"Actor Loss\")"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "8ec3163f43658331"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "list(critic.v.parameters())[0]"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "98d6247f212435cf"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "list(actor.pi.parameters())[0]"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "8642abe359a34b8d"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "returns[:][:j]"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "90ea1a4b45b3efb0"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "dump()"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "12514dda01e24ddf"
  },
  {
   "cell_type": "markdown",
   "source": [
    "<h3> Evaluate in human render mode </h3>"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "1b39d92e97101cb3"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "actor,critic,scaler = load()\n",
    "env = gymnasium.make(\"MountainCarContinuous-v0\",render_mode=\"human\")\n",
    "state,*_ = env.reset()\n",
    "for _ in range(1):\n",
    "    state = np.squeeze(scaler.transform([state]))\n",
    "    state = torch.from_numpy(state).detach().float()\n",
    "    with torch.no_grad():\n",
    "        action = actor.sample(state)\n",
    "    next_state,reward,terminated = env.step(action)\n",
    "    state = next_state"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "5c9a68065b248880"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
