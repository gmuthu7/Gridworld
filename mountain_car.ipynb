{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "<h1> Advantage Actor Critic on continuous actions </h1>\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "13f55af02d21206a"
  },
  {
   "cell_type": "markdown",
   "source": [
    "<h3> Import dependencies </h3>"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "e745491f8f1a5f6a"
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2023-09-24T17:41:56.726887Z",
     "start_time": "2023-09-24T17:41:55.171338Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "<torch.autograd.grad_mode.set_grad_enabled at 0x137998610>"
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import gymnasium\n",
    "from tqdm import tqdm\n",
    "from matplotlib.axes import Axes\n",
    "from matplotlib.figure import Figure\n",
    "import torch\n",
    "from torch import nn\n",
    "import cloudpickle\n",
    "import sklearn\n",
    "from sklearn import preprocessing\n",
    "torch.set_grad_enabled(True) "
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "<h3> Helper functions </h3>"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "3f5d4c5608659f00"
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "def get_grads(model:torch.nn.Module):\n",
    "    g = [param.grad.flatten() for param in model.parameters() if param.grad is not None]\n",
    "    g = torch.cat(g).norm()\n",
    "    return g"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-09-24T17:42:00.569876Z",
     "start_time": "2023-09-24T17:42:00.562235Z"
    }
   },
   "id": "3fcd9d82bbfb36c7"
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "def dump():\n",
    "    with (open(\"./models/actor.pkl\",\"wb\") as f1, \n",
    "          open(\"./models/critic.pkl\",\"wb\") as f2):\n",
    "        cloudpickle.dump(actor,f1)\n",
    "        cloudpickle.dump(critic,f2)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-09-24T17:42:01.205544Z",
     "start_time": "2023-09-24T17:42:01.196576Z"
    }
   },
   "id": "a4557cabafea6326"
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "def load():\n",
    "    with (open(\"./models/actor.pkl\",\"rb\") as f1, \n",
    "          open(\"./models/critic.pkl\",\"rb\") as f2):\n",
    "        actor = cloudpickle.load(f1)\n",
    "        critic = cloudpickle.load(f2)\n",
    "        return actor,critic"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-09-24T17:42:05.064464Z",
     "start_time": "2023-09-24T17:42:05.060552Z"
    }
   },
   "id": "857a38406a5206c0"
  },
  {
   "cell_type": "markdown",
   "source": [
    "<h3> Actor critic helper classes </h3>"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "20c5eaa5251e8b7b"
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [],
   "source": [
    "class Actor:\n",
    "    def __init__(self):\n",
    "        self.pi = nn.Sequential(nn.Linear(2,50),\n",
    "                  nn.ReLU(),\n",
    "                  nn.Linear(50,2))\n",
    "        \n",
    "    def log_prob(self,state,action):\n",
    "        dist =self._get_dist(state)\n",
    "        return dist.log_prob(action)\n",
    "    \n",
    "    def sample(self,state):\n",
    "        dist =self._get_dist(state)\n",
    "        _sample = dist.sample((1,))\n",
    "        return _sample\n",
    "    \n",
    "    def _get_dist(self,state):\n",
    "        mu,sigma = self.pi(state)\n",
    "        sigma = torch.nn.Softplus()(sigma) + 1e-1\n",
    "        dist = torch.distributions.Normal(mu,sigma)\n",
    "        return dist"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-09-24T17:42:17.546184Z",
     "start_time": "2023-09-24T17:42:17.539241Z"
    }
   },
   "id": "748dcd157f21d3d6"
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [],
   "source": [
    "class Critic:\n",
    "    def __init__(self):\n",
    "        self.v = nn.Sequential(nn.Linear(2,100),\n",
    "                  nn.ReLU(),\n",
    "                  nn.Linear(100,1))\n",
    "    \n",
    "    def val(self,state):\n",
    "        _val = self.v(state)\n",
    "        return _val\n",
    "    "
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-09-24T17:42:18.154100Z",
     "start_time": "2023-09-24T17:42:18.150669Z"
    }
   },
   "id": "1cd6bbbaae5da9fa"
  },
  {
   "cell_type": "markdown",
   "source": [
    "<h3> Implementation of A2C </h3>"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "f90f23ad56de23c4"
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[5], line 37\u001B[0m\n\u001B[1;32m     35\u001B[0m updates\u001B[38;5;241m+\u001B[39m\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m1\u001B[39m\n\u001B[1;32m     36\u001B[0m rewards\u001B[38;5;241m.\u001B[39mappend(reward)\n\u001B[0;32m---> 37\u001B[0m reward\u001B[38;5;241m-\u001B[39m\u001B[38;5;241m=\u001B[39m \u001B[43mnp\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mmean\u001B[49m\u001B[43m(\u001B[49m\u001B[43mrewards\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m     38\u001B[0m reward\u001B[38;5;241m/\u001B[39m\u001B[38;5;241m=\u001B[39m (np\u001B[38;5;241m.\u001B[39mstd(rewards)\u001B[38;5;241m+\u001B[39m\u001B[38;5;241m1e-3\u001B[39m)\n\u001B[1;32m     39\u001B[0m next_state \u001B[38;5;241m=\u001B[39m np\u001B[38;5;241m.\u001B[39msqueeze(scaler\u001B[38;5;241m.\u001B[39mtransform([next_state]))\n",
      "File \u001B[0;32m~/Library/Caches/pypoetry/virtualenvs/gridworld-1-zk00QJ-py3.11/lib/python3.11/site-packages/numpy/core/fromnumeric.py:3504\u001B[0m, in \u001B[0;36mmean\u001B[0;34m(a, axis, dtype, out, keepdims, where)\u001B[0m\n\u001B[1;32m   3501\u001B[0m     \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m   3502\u001B[0m         \u001B[38;5;28;01mreturn\u001B[39;00m mean(axis\u001B[38;5;241m=\u001B[39maxis, dtype\u001B[38;5;241m=\u001B[39mdtype, out\u001B[38;5;241m=\u001B[39mout, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n\u001B[0;32m-> 3504\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43m_methods\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_mean\u001B[49m\u001B[43m(\u001B[49m\u001B[43ma\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43maxis\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43maxis\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mdtype\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mdtype\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   3505\u001B[0m \u001B[43m                      \u001B[49m\u001B[43mout\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mout\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/Library/Caches/pypoetry/virtualenvs/gridworld-1-zk00QJ-py3.11/lib/python3.11/site-packages/numpy/core/_methods.py:102\u001B[0m, in \u001B[0;36m_mean\u001B[0;34m(a, axis, dtype, out, keepdims, where)\u001B[0m\n\u001B[1;32m    101\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21m_mean\u001B[39m(a, axis\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mNone\u001B[39;00m, dtype\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mNone\u001B[39;00m, out\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mNone\u001B[39;00m, keepdims\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mFalse\u001B[39;00m, \u001B[38;5;241m*\u001B[39m, where\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mTrue\u001B[39;00m):\n\u001B[0;32m--> 102\u001B[0m     arr \u001B[38;5;241m=\u001B[39m asanyarray(a)\n\u001B[1;32m    104\u001B[0m     is_float16_result \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mFalse\u001B[39;00m\n\u001B[1;32m    106\u001B[0m     rcount \u001B[38;5;241m=\u001B[39m _count_reduce_items(arr, axis, keepdims\u001B[38;5;241m=\u001B[39mkeepdims, where\u001B[38;5;241m=\u001B[39mwhere)\n",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "source": [
    "NUM_EPISODES = 1000\n",
    "ALPHA_V = ALPHA_PI = 0.1\n",
    "GAMMA = 1\n",
    "env = gymnasium.make(\"MountainCarContinuous-v0\")\n",
    "mse_loss = nn.MSELoss()\n",
    "actor = Actor()\n",
    "critic = Critic()\n",
    "pi_op = torch.optim.AdamW(actor.pi.parameters(),lr=ALPHA_PI)\n",
    "v_op = torch.optim.AdamW(critic.v.parameters(),lr=ALPHA_V)\n",
    "returns = []\n",
    "ep_lens = []\n",
    "for j in range(NUM_EPISODES):\n",
    "    log_probs = []\n",
    "    values = []\n",
    "    rewards = []\n",
    "    state,*_ = env.reset()\n",
    "    state = torch.as_tensor(state).float()\n",
    "    while True:\n",
    "        action = actor.sample(state)\n",
    "        action = torch.clamp(action,env.action_space.low[0],env.action_space.high[0])\n",
    "        next_state,reward,terminated,truncated,*_ = env.step(action)\n",
    "        next_state = torch.as_tensor(next_state).float()\n",
    "        log_prob = actor.log_prob(state,action)\n",
    "        value = critic.val(state)\n",
    "        log_probs.append(log_prob)\n",
    "        rewards.append(reward)\n",
    "        values.append(value)\n",
    "        state = next_state\n",
    "        if terminated or truncated:\n",
    "            ret = np.sum(rewards)\n",
    "            if terminated:\n",
    "                print(\"Achieved target in\",len(values),\"steps at ep\",j,\"with ret\",ret)\n",
    "            break\n",
    "    \n",
    "    returns.append(np.sum(rewards))\n",
    "    ep_lens.append(ep_len)\n",
    "    target = torch.tensor([reward],dtype=torch.float) + GAMMA * (critic.val(next_state) if not terminated else 0)\n",
    "    v_op.zero_grad()\n",
    "    est_v = critic.val(state)\n",
    "    loss = mse_loss(target.detach(),est_v)\n",
    "    loss.backward()\n",
    "    v_op.step()\n",
    "    critic_est = torch.tensor([reward],dtype=torch.float) + GAMMA*(critic.val(next_state) if not terminated else 0) - critic.val(state)\n",
    "    pi_op.zero_grad()\n",
    "    prob = actor.log_prob(state,action)\n",
    "    loss = critic_est.detach()*prob[0]*-1 \n",
    "    loss.backward()\n",
    "    pi_op.step()\n",
    "        "
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-09-21T12:33:16.744472Z",
     "start_time": "2023-09-21T12:32:45.831615Z"
    }
   },
   "id": "c0f9081d0cf83eb7"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "fig:Figure\n",
    "ax1:Axes\n",
    "ax2:Axes\n",
    "ax3:Axes\n",
    "ax4:Axes\n",
    "ax5:Axes\n",
    "ax6:Axes\n",
    "fig,((ax1,ax2),(ax3,ax4),(ax5,ax6),(ax7,ax8)) = plt.subplots(4,2)\n",
    "fig.set_figwidth(20)\n",
    "fig.set_figheight(20)\n",
    "fig.tight_layout(pad=5.0)\n",
    "ax1.plot(returns[:j])\n",
    "ax1.set_ylabel(f\"Mean return {NUM_TRIALS} trials\")\n",
    "ax1.set_xlabel(\"Episode\")\n",
    "ax1.set_title(\"Mean Return\")\n",
    "ax2.plot(ep_lens[:j])\n",
    "ax2.set_ylabel(f\"Mean episode length {NUM_TRIALS} trials\")\n",
    "ax2.set_xlabel(\"Episode\")\n",
    "ax2.set_title(\"Mean Episode Length\")\n",
    "ax3.plot(grads[0])\n",
    "ax3.set_ylabel(f\"Grad Norm\")\n",
    "ax3.set_xlabel(\"Grad Index\")\n",
    "ax3.set_title(\"Critic Grad Norm\")\n",
    "ax4.plot(losses[0])\n",
    "ax4.set_ylabel(f\"Loss\")\n",
    "ax4.set_xlabel(\"Loss Index\")\n",
    "ax4.set_title(\"Critic Loss\")\n",
    "ax5.plot(grads[1])\n",
    "ax5.set_ylabel(f\"Grad Norm\")\n",
    "ax5.set_xlabel(\"Grad Index\")\n",
    "ax5.set_title(\"Actor Grad Norm\")\n",
    "ax6.plot(losses[1])\n",
    "ax6.set_ylabel(f\"Loss\")\n",
    "ax6.set_xlabel(\"Loss Index\")\n",
    "ax6.set_title(\"Actor Loss\");\n",
    "ax7.plot(entropies)\n",
    "ax7.set_ylabel(f\"Entropy\")\n",
    "ax7.set_xlabel(\"Index\")\n",
    "ax7.set_title(\"Entropy Loss\");\n",
    "ax8.plot(rewards)\n",
    "ax8.set_ylabel(f\"Rewards\")\n",
    "ax8.set_xlabel(\"Index\")\n",
    "ax8.set_title(\"Rewards\");"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-09-21T12:33:16.745383Z"
    }
   },
   "id": "8ec3163f43658331"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "list(critic.v.parameters())[0]"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-09-21T12:33:16.748261Z",
     "start_time": "2023-09-21T12:33:16.746361Z"
    }
   },
   "id": "98d6247f212435cf"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "list(actor.pi.parameters())[0]"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-09-21T12:33:16.747764Z"
    }
   },
   "id": "8642abe359a34b8d"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "returns[:,:j]"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-09-21T12:33:16.749023Z"
    }
   },
   "id": "90ea1a4b45b3efb0"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "dump()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-09-21T12:33:16.750143Z"
    }
   },
   "id": "12514dda01e24ddf"
  },
  {
   "cell_type": "markdown",
   "source": [
    "<h3> Evaluate in human render mode </h3>"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "1b39d92e97101cb3"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "actor,critic,scaler = load()\n",
    "env = gymnasium.make(\"MountainCarContinuous-v0\",render_mode=\"human\")\n",
    "for _ in range(10):\n",
    "    state,*_ = env.reset()\n",
    "    while True:\n",
    "        state = np.squeeze(scaler.transform([state]))\n",
    "        state = torch.from_numpy(state).detach().float()\n",
    "        with torch.no_grad():\n",
    "            action = actor.sample(state)\n",
    "        next_state,reward,terminated,truncated,*_ = env.step(action)\n",
    "        if terminated or terminated:\n",
    "            break\n",
    "        state = next_state"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-09-21T12:33:16.751098Z"
    }
   },
   "id": "5c9a68065b248880"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-09-21T12:33:16.751689Z"
    }
   },
   "id": "4e300aaf2ed574e5"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
