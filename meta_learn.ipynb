{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2023-10-06T05:54:51.937663Z",
     "start_time": "2023-10-06T05:54:47.120668Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "<torch.autograd.grad_mode.set_grad_enabled at 0x14f56bbd0>"
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import random\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import gymnasium\n",
    "from tqdm import tqdm\n",
    "from matplotlib.axes import Axes\n",
    "from matplotlib.figure import Figure\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import torch.distributions as dist\n",
    "from torch import nn\n",
    "import cloudpickle\n",
    "import sklearn\n",
    "from sklearn import preprocessing\n",
    "torch.set_grad_enabled(True) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 311,
   "outputs": [],
   "source": [
    "class Network(torch.nn.Module):\n",
    "    def __init__(self,num_inputs,num_outputs):\n",
    "        super().__init__()\n",
    "        self.network = nn.Sequential(\n",
    "            nn.Linear(num_inputs,256),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(256,256),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(256,256),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(256,256),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(256,256),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(256,num_outputs)\n",
    "        )\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = self.network(x)\n",
    "        return x"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-09-22T07:10:10.197345Z",
     "start_time": "2023-09-22T07:10:10.191168Z"
    }
   },
   "id": "71fb607b7e539023"
  },
  {
   "cell_type": "code",
   "execution_count": 312,
   "outputs": [],
   "source": [
    "def seed(s:int):\n",
    "    random.seed(s)\n",
    "    torch.manual_seed(s)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-09-22T07:10:10.605136Z",
     "start_time": "2023-09-22T07:10:10.601238Z"
    }
   },
   "id": "acaa339efe891711"
  },
  {
   "cell_type": "code",
   "execution_count": 313,
   "outputs": [],
   "source": [
    "def train_one_step(network: Network,optim:torch.optim.Optimizer, x:torch.Tensor,y:torch.Tensor):\n",
    "    network.train()\n",
    "    out = network(x)\n",
    "    loss = F.mse_loss(y.detach(),out)\n",
    "    optim.zero_grad()\n",
    "    loss.backward()\n",
    "    optim.step()\n",
    "    return loss.item()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-09-22T07:10:11.030648Z",
     "start_time": "2023-09-22T07:10:11.027015Z"
    }
   },
   "id": "fdf4fb110f714b1a"
  },
  {
   "cell_type": "code",
   "execution_count": 314,
   "outputs": [],
   "source": [
    "def eval_one_step(network:Network,x:torch.Tensor,y:torch.Tensor):\n",
    "    network.eval()\n",
    "    with torch.no_grad():\n",
    "        out = network(x)\n",
    "        loss = F.mse_loss(y,out)\n",
    "    return loss.item()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-09-22T07:10:13.079808Z",
     "start_time": "2023-09-22T07:10:13.070481Z"
    }
   },
   "id": "c3a1550d8fb98073"
  },
  {
   "cell_type": "markdown",
   "source": [
    "<h1> MLE of linear regression </h1>"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "570dfbd8f808a223"
  },
  {
   "cell_type": "code",
   "execution_count": 315,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| Loss at epoch     0 is  0.00293 Best Loss 1000.00000 |\n",
      "| Loss at epoch   100 is  0.00095 Best Loss 0.00293 |\n",
      "| Loss at epoch   200 is  0.00104 Best Loss 0.00095 |\n",
      "| Loss at epoch   300 is  0.00107 Best Loss 0.00095 |\n",
      "| Loss at epoch   400 is  0.00095 Best Loss 0.00095 |\n",
      "| Loss at epoch   500 is  0.00114 Best Loss 0.00095 |\n",
      "| Loss at epoch   600 is  0.00109 Best Loss 0.00095 |\n",
      "| Loss at epoch   700 is  0.00107 Best Loss 0.00095 |\n",
      "| Loss at epoch   800 is  0.00094 Best Loss 0.00095 |\n",
      "| Loss at epoch   900 is  0.00096 Best Loss 0.00094 |\n",
      "| Loss at epoch  1000 is  0.00096 Best Loss 0.00094 |\n",
      "| Loss at epoch  1100 is  0.00094 Best Loss 0.00094 |\n",
      "| Loss at epoch  1200 is  0.00103 Best Loss 0.00094 |\n",
      "| Loss at epoch  1300 is  0.00104 Best Loss 0.00094 |\n",
      "| Loss at epoch  1400 is  0.00106 Best Loss 0.00094 |\n",
      "| Loss at epoch  1500 is  0.00103 Best Loss 0.00094 |\n",
      "| Loss at epoch  1600 is  0.00111 Best Loss 0.00094 |\n",
      "| Loss at epoch  1700 is  0.00101 Best Loss 0.00094 |\n",
      "| Loss at epoch  1800 is  0.00107 Best Loss 0.00094 |\n",
      "| Loss at epoch  1900 is  0.00111 Best Loss 0.00094 |\n",
      "| Loss at epoch  2000 is  0.00116 Best Loss 0.00094 |\n",
      "| Loss at epoch  2100 is  0.00108 Best Loss 0.00094 |\n",
      "| Loss at epoch  2200 is  0.00101 Best Loss 0.00094 |\n",
      "| Loss at epoch  2300 is  0.00100 Best Loss 0.00094 |\n",
      "| Loss at epoch  2400 is  0.00095 Best Loss 0.00094 |\n",
      "| Loss at epoch  2500 is  0.00107 Best Loss 0.00094 |\n",
      "| Loss at epoch  2600 is  0.00098 Best Loss 0.00094 |\n",
      "| Loss at epoch  2700 is  0.00105 Best Loss 0.00094 |\n",
      "| Loss at epoch  2800 is  0.00099 Best Loss 0.00094 |\n",
      "| Loss at epoch  2900 is  0.00099 Best Loss 0.00094 |\n",
      "| Loss at epoch  3000 is  0.00097 Best Loss 0.00094 |\n",
      "| Loss at epoch  3100 is  0.00097 Best Loss 0.00094 |\n",
      "| Loss at epoch  3200 is  0.00108 Best Loss 0.00094 |\n",
      "| Loss at epoch  3300 is  0.00101 Best Loss 0.00094 |\n",
      "| Loss at epoch  3400 is  0.00109 Best Loss 0.00094 |\n",
      "| Loss at epoch  3500 is  0.00104 Best Loss 0.00094 |\n",
      "| Loss at epoch  3600 is  0.00110 Best Loss 0.00094 |\n",
      "| Loss at epoch  3700 is  0.00098 Best Loss 0.00094 |\n",
      "| Loss at epoch  3800 is  0.00094 Best Loss 0.00094 |\n",
      "| Loss at epoch  3900 is  0.00101 Best Loss 0.00094 |\n",
      "| Loss at epoch  4000 is  0.00099 Best Loss 0.00094 |\n",
      "| Loss at epoch  4100 is  0.00105 Best Loss 0.00094 |\n",
      "| Loss at epoch  4200 is  0.00100 Best Loss 0.00094 |\n",
      "| Loss at epoch  4300 is  0.00120 Best Loss 0.00094 |\n",
      "| Loss at epoch  4400 is  0.00107 Best Loss 0.00094 |\n",
      "| Loss at epoch  4500 is  0.00096 Best Loss 0.00094 |\n",
      "| Loss at epoch  4600 is  0.00103 Best Loss 0.00094 |\n",
      "| Loss at epoch  4700 is  0.00104 Best Loss 0.00094 |\n",
      "| Loss at epoch  4800 is  0.00113 Best Loss 0.00094 |\n",
      "| Loss at epoch  4900 is  0.00090 Best Loss 0.00094 |\n",
      "| Loss at epoch  5000 is  0.00104 Best Loss 0.00090 |\n",
      "| Loss at epoch  5100 is  0.00108 Best Loss 0.00090 |\n",
      "| Loss at epoch  5200 is  0.00099 Best Loss 0.00090 |\n",
      "| Loss at epoch  5300 is  0.00100 Best Loss 0.00090 |\n",
      "| Loss at epoch  5400 is  0.00100 Best Loss 0.00090 |\n",
      "| Loss at epoch  5500 is  0.00102 Best Loss 0.00090 |\n",
      "| Loss at epoch  5600 is  0.00094 Best Loss 0.00090 |\n",
      "| Loss at epoch  5700 is  0.00100 Best Loss 0.00090 |\n",
      "| Loss at epoch  5800 is  0.00100 Best Loss 0.00090 |\n",
      "| Loss at epoch  5900 is  0.00111 Best Loss 0.00090 |\n",
      "| Loss at epoch  6000 is  0.00097 Best Loss 0.00090 |\n",
      "| Loss at epoch  6100 is  0.00112 Best Loss 0.00090 |\n",
      "| Loss at epoch  6200 is  0.00111 Best Loss 0.00090 |\n",
      "| Loss at epoch  6300 is  0.00112 Best Loss 0.00090 |\n",
      "| Loss at epoch  6400 is  0.00109 Best Loss 0.00090 |\n",
      "| Loss at epoch  6500 is  0.00094 Best Loss 0.00090 |\n",
      "| Loss at epoch  6600 is  0.00101 Best Loss 0.00090 |\n",
      "| Loss at epoch  6700 is  0.00105 Best Loss 0.00090 |\n",
      "| Loss at epoch  6800 is  0.00095 Best Loss 0.00090 |\n",
      "| Loss at epoch  6900 is  0.00096 Best Loss 0.00090 |\n",
      "| Loss at epoch  7000 is  0.00092 Best Loss 0.00090 |\n",
      "| Loss at epoch  7100 is  0.00106 Best Loss 0.00090 |\n",
      "| Loss at epoch  7200 is  0.00107 Best Loss 0.00090 |\n",
      "| Loss at epoch  7300 is  0.00095 Best Loss 0.00090 |\n",
      "| Loss at epoch  7400 is  0.00096 Best Loss 0.00090 |\n",
      "| Loss at epoch  7500 is  0.00102 Best Loss 0.00090 |\n",
      "| Loss at epoch  7600 is  0.00107 Best Loss 0.00090 |\n",
      "| Loss at epoch  7700 is  0.00096 Best Loss 0.00090 |\n",
      "| Loss at epoch  7800 is  0.00100 Best Loss 0.00090 |\n",
      "| Loss at epoch  7900 is  0.00096 Best Loss 0.00090 |\n",
      "| Loss at epoch  8000 is  0.00088 Best Loss 0.00090 |\n",
      "| Loss at epoch  8100 is  0.00103 Best Loss 0.00088 |\n",
      "| Loss at epoch  8200 is  0.00110 Best Loss 0.00088 |\n",
      "| Loss at epoch  8300 is  0.00094 Best Loss 0.00088 |\n",
      "| Loss at epoch  8400 is  0.00113 Best Loss 0.00088 |\n",
      "| Loss at epoch  8500 is  0.00105 Best Loss 0.00088 |\n",
      "| Loss at epoch  8600 is  0.00100 Best Loss 0.00088 |\n",
      "| Loss at epoch  8700 is  0.00103 Best Loss 0.00088 |\n",
      "| Loss at epoch  8800 is  0.00107 Best Loss 0.00088 |\n",
      "| Loss at epoch  8900 is  0.00094 Best Loss 0.00088 |\n",
      "| Loss at epoch  9000 is  0.00090 Best Loss 0.00088 |\n",
      "| Loss at epoch  9100 is  0.00103 Best Loss 0.00088 |\n",
      "| Loss at epoch  9200 is  0.00117 Best Loss 0.00088 |\n",
      "| Loss at epoch  9300 is  0.00102 Best Loss 0.00088 |\n",
      "| Loss at epoch  9400 is  0.00098 Best Loss 0.00088 |\n",
      "| Loss at epoch  9500 is  0.00100 Best Loss 0.00088 |\n",
      "| Loss at epoch  9600 is  0.00102 Best Loss 0.00088 |\n",
      "| Loss at epoch  9700 is  0.00100 Best Loss 0.00088 |\n",
      "| Loss at epoch  9800 is  0.00107 Best Loss 0.00088 |\n",
      "| Loss at epoch  9900 is  0.00101 Best Loss 0.00088 |\n",
      "| Loss at epoch 10000 is  0.00102 Best Loss 0.00088 |\n",
      "| Loss at epoch 10100 is  0.00098 Best Loss 0.00088 |\n",
      "| Loss at epoch 10200 is  0.00102 Best Loss 0.00088 |\n",
      "| Loss at epoch 10300 is  0.00092 Best Loss 0.00088 |\n",
      "| Loss at epoch 10400 is  0.00106 Best Loss 0.00088 |\n",
      "| Loss at epoch 10500 is  0.00096 Best Loss 0.00088 |\n",
      "| Loss at epoch 10600 is  0.00103 Best Loss 0.00088 |\n",
      "| Loss at epoch 10700 is  0.00095 Best Loss 0.00088 |\n",
      "| Loss at epoch 10800 is  0.00098 Best Loss 0.00088 |\n",
      "| Loss at epoch 10900 is  0.00107 Best Loss 0.00088 |\n",
      "| Loss at epoch 11000 is  0.00108 Best Loss 0.00088 |\n",
      "| Loss at epoch 11100 is  0.00099 Best Loss 0.00088 |\n",
      "| Loss at epoch 11200 is  0.00099 Best Loss 0.00088 |\n",
      "| Loss at epoch 11300 is  0.00100 Best Loss 0.00088 |\n",
      "| Loss at epoch 11400 is  0.00099 Best Loss 0.00088 |\n",
      "| Loss at epoch 11500 is  0.00093 Best Loss 0.00088 |\n",
      "| Loss at epoch 11600 is  0.00104 Best Loss 0.00088 |\n",
      "| Loss at epoch 11700 is  0.00102 Best Loss 0.00088 |\n",
      "| Loss at epoch 11800 is  0.00105 Best Loss 0.00088 |\n",
      "| Loss at epoch 11900 is  0.00098 Best Loss 0.00088 |\n",
      "| Loss at epoch 12000 is  0.00104 Best Loss 0.00088 |\n",
      "| Loss at epoch 12100 is  0.00102 Best Loss 0.00088 |\n",
      "| Loss at epoch 12200 is  0.00100 Best Loss 0.00088 |\n",
      "| Loss at epoch 12300 is  0.00100 Best Loss 0.00088 |\n",
      "| Loss at epoch 12400 is  0.00104 Best Loss 0.00088 |\n",
      "| Loss at epoch 12500 is  0.00110 Best Loss 0.00088 |\n",
      "| Loss at epoch 12600 is  0.00097 Best Loss 0.00088 |\n",
      "| Loss at epoch 12700 is  0.00107 Best Loss 0.00088 |\n",
      "| Loss at epoch 12800 is  0.00100 Best Loss 0.00088 |\n",
      "| Loss at epoch 12900 is  0.00104 Best Loss 0.00088 |\n",
      "| Loss at epoch 13000 is  0.00103 Best Loss 0.00088 |\n",
      "| Loss at epoch 13100 is  0.00105 Best Loss 0.00088 |\n",
      "| Loss at epoch 13200 is  0.00101 Best Loss 0.00088 |\n",
      "| Loss at epoch 13300 is  0.00098 Best Loss 0.00088 |\n",
      "| Loss at epoch 13400 is  0.00113 Best Loss 0.00088 |\n",
      "| Loss at epoch 13500 is  0.00099 Best Loss 0.00088 |\n",
      "| Loss at epoch 13600 is  0.00110 Best Loss 0.00088 |\n",
      "| Loss at epoch 13700 is  0.00098 Best Loss 0.00088 |\n",
      "| Loss at epoch 13800 is  0.00099 Best Loss 0.00088 |\n",
      "| Loss at epoch 13900 is  0.00111 Best Loss 0.00088 |\n",
      "| Loss at epoch 14000 is  0.00090 Best Loss 0.00088 |\n",
      "| Loss at epoch 14100 is  0.00095 Best Loss 0.00088 |\n",
      "| Loss at epoch 14200 is  0.00110 Best Loss 0.00088 |\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[E thread_pool.cpp:109] Exception in thread pool task: mutex lock failed: Invalid argument\n",
      "[E thread_pool.cpp:109] Exception in thread pool task: mutex lock failed: Invalid argument\n",
      "[E thread_pool.cpp:109] Exception in thread pool task: mutex lock failed: Invalid argument\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[315], line 21\u001B[0m\n\u001B[1;32m     19\u001B[0m     theta \u001B[38;5;241m=\u001B[39m torch\u001B[38;5;241m.\u001B[39minverse(x\u001B[38;5;241m.\u001B[39mT\u001B[38;5;129m@x\u001B[39m \u001B[38;5;241m+\u001B[39m (\u001B[38;5;241m1e-5\u001B[39m)\u001B[38;5;241m*\u001B[39mtorch\u001B[38;5;241m.\u001B[39meye(OBS_SIZE))\u001B[38;5;129m@x\u001B[39m\u001B[38;5;241m.\u001B[39mT\u001B[38;5;129m@y\u001B[39m\n\u001B[1;32m     20\u001B[0m     theta_batch[j] \u001B[38;5;241m=\u001B[39m theta\n\u001B[0;32m---> 21\u001B[0m loss \u001B[38;5;241m=\u001B[39m \u001B[43mtrain_one_step\u001B[49m\u001B[43m(\u001B[49m\u001B[43mnetwork\u001B[49m\u001B[43m,\u001B[49m\u001B[43moptim\u001B[49m\u001B[43m,\u001B[49m\u001B[43mobs_batch\u001B[49m\u001B[43m,\u001B[49m\u001B[43mtheta_batch\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m     22\u001B[0m loss_lst\u001B[38;5;241m.\u001B[39mappend(loss)\n\u001B[1;32m     23\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m i\u001B[38;5;241m%\u001B[39m\u001B[38;5;241m100\u001B[39m \u001B[38;5;241m==\u001B[39m \u001B[38;5;241m0\u001B[39m:\n",
      "Cell \u001B[0;32mIn[313], line 7\u001B[0m, in \u001B[0;36mtrain_one_step\u001B[0;34m(network, optim, x, y)\u001B[0m\n\u001B[1;32m      5\u001B[0m optim\u001B[38;5;241m.\u001B[39mzero_grad()\n\u001B[1;32m      6\u001B[0m loss\u001B[38;5;241m.\u001B[39mbackward()\n\u001B[0;32m----> 7\u001B[0m \u001B[43moptim\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mstep\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m      8\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m loss\u001B[38;5;241m.\u001B[39mitem()\n",
      "File \u001B[0;32m~/Library/Caches/pypoetry/virtualenvs/gridworld-1-zk00QJ-py3.11/lib/python3.11/site-packages/torch/optim/optimizer.py:280\u001B[0m, in \u001B[0;36mOptimizer.profile_hook_step.<locals>.wrapper\u001B[0;34m(*args, **kwargs)\u001B[0m\n\u001B[1;32m    276\u001B[0m         \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m    277\u001B[0m             \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mRuntimeError\u001B[39;00m(\u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;132;01m{\u001B[39;00mfunc\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m must return None or a tuple of (new_args, new_kwargs),\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m    278\u001B[0m                                \u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mbut got \u001B[39m\u001B[38;5;132;01m{\u001B[39;00mresult\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m.\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n\u001B[0;32m--> 280\u001B[0m out \u001B[38;5;241m=\u001B[39m \u001B[43mfunc\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    281\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_optimizer_step_code()\n\u001B[1;32m    283\u001B[0m \u001B[38;5;66;03m# call optimizer step post hooks\u001B[39;00m\n",
      "File \u001B[0;32m~/Library/Caches/pypoetry/virtualenvs/gridworld-1-zk00QJ-py3.11/lib/python3.11/site-packages/torch/optim/optimizer.py:33\u001B[0m, in \u001B[0;36m_use_grad_for_differentiable.<locals>._use_grad\u001B[0;34m(self, *args, **kwargs)\u001B[0m\n\u001B[1;32m     31\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[1;32m     32\u001B[0m     torch\u001B[38;5;241m.\u001B[39mset_grad_enabled(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mdefaults[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mdifferentiable\u001B[39m\u001B[38;5;124m'\u001B[39m])\n\u001B[0;32m---> 33\u001B[0m     ret \u001B[38;5;241m=\u001B[39m \u001B[43mfunc\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m     34\u001B[0m \u001B[38;5;28;01mfinally\u001B[39;00m:\n\u001B[1;32m     35\u001B[0m     torch\u001B[38;5;241m.\u001B[39mset_grad_enabled(prev_grad)\n",
      "File \u001B[0;32m~/Library/Caches/pypoetry/virtualenvs/gridworld-1-zk00QJ-py3.11/lib/python3.11/site-packages/torch/optim/sgd.py:76\u001B[0m, in \u001B[0;36mSGD.step\u001B[0;34m(self, closure)\u001B[0m\n\u001B[1;32m     72\u001B[0m momentum_buffer_list \u001B[38;5;241m=\u001B[39m []\n\u001B[1;32m     74\u001B[0m has_sparse_grad \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_init_group(group, params_with_grad, d_p_list, momentum_buffer_list)\n\u001B[0;32m---> 76\u001B[0m \u001B[43msgd\u001B[49m\u001B[43m(\u001B[49m\u001B[43mparams_with_grad\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m     77\u001B[0m \u001B[43m    \u001B[49m\u001B[43md_p_list\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m     78\u001B[0m \u001B[43m    \u001B[49m\u001B[43mmomentum_buffer_list\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m     79\u001B[0m \u001B[43m    \u001B[49m\u001B[43mweight_decay\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mgroup\u001B[49m\u001B[43m[\u001B[49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43mweight_decay\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[43m]\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m     80\u001B[0m \u001B[43m    \u001B[49m\u001B[43mmomentum\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mgroup\u001B[49m\u001B[43m[\u001B[49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43mmomentum\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[43m]\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m     81\u001B[0m \u001B[43m    \u001B[49m\u001B[43mlr\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mgroup\u001B[49m\u001B[43m[\u001B[49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43mlr\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[43m]\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m     82\u001B[0m \u001B[43m    \u001B[49m\u001B[43mdampening\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mgroup\u001B[49m\u001B[43m[\u001B[49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43mdampening\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[43m]\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m     83\u001B[0m \u001B[43m    \u001B[49m\u001B[43mnesterov\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mgroup\u001B[49m\u001B[43m[\u001B[49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43mnesterov\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[43m]\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m     84\u001B[0m \u001B[43m    \u001B[49m\u001B[43mmaximize\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mgroup\u001B[49m\u001B[43m[\u001B[49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43mmaximize\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[43m]\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m     85\u001B[0m \u001B[43m    \u001B[49m\u001B[43mhas_sparse_grad\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mhas_sparse_grad\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m     86\u001B[0m \u001B[43m    \u001B[49m\u001B[43mforeach\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mgroup\u001B[49m\u001B[43m[\u001B[49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43mforeach\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[43m]\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m     88\u001B[0m \u001B[38;5;66;03m# update momentum_buffers in state\u001B[39;00m\n\u001B[1;32m     89\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m p, momentum_buffer \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mzip\u001B[39m(params_with_grad, momentum_buffer_list):\n",
      "File \u001B[0;32m~/Library/Caches/pypoetry/virtualenvs/gridworld-1-zk00QJ-py3.11/lib/python3.11/site-packages/torch/optim/sgd.py:222\u001B[0m, in \u001B[0;36msgd\u001B[0;34m(params, d_p_list, momentum_buffer_list, has_sparse_grad, foreach, weight_decay, momentum, lr, dampening, nesterov, maximize)\u001B[0m\n\u001B[1;32m    219\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m    220\u001B[0m     func \u001B[38;5;241m=\u001B[39m _single_tensor_sgd\n\u001B[0;32m--> 222\u001B[0m \u001B[43mfunc\u001B[49m\u001B[43m(\u001B[49m\u001B[43mparams\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    223\u001B[0m \u001B[43m     \u001B[49m\u001B[43md_p_list\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    224\u001B[0m \u001B[43m     \u001B[49m\u001B[43mmomentum_buffer_list\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    225\u001B[0m \u001B[43m     \u001B[49m\u001B[43mweight_decay\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mweight_decay\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    226\u001B[0m \u001B[43m     \u001B[49m\u001B[43mmomentum\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mmomentum\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    227\u001B[0m \u001B[43m     \u001B[49m\u001B[43mlr\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mlr\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    228\u001B[0m \u001B[43m     \u001B[49m\u001B[43mdampening\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mdampening\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    229\u001B[0m \u001B[43m     \u001B[49m\u001B[43mnesterov\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mnesterov\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    230\u001B[0m \u001B[43m     \u001B[49m\u001B[43mhas_sparse_grad\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mhas_sparse_grad\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    231\u001B[0m \u001B[43m     \u001B[49m\u001B[43mmaximize\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mmaximize\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/Library/Caches/pypoetry/virtualenvs/gridworld-1-zk00QJ-py3.11/lib/python3.11/site-packages/torch/optim/sgd.py:265\u001B[0m, in \u001B[0;36m_single_tensor_sgd\u001B[0;34m(params, d_p_list, momentum_buffer_list, weight_decay, momentum, lr, dampening, nesterov, maximize, has_sparse_grad)\u001B[0m\n\u001B[1;32m    262\u001B[0m     \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m    263\u001B[0m         d_p \u001B[38;5;241m=\u001B[39m buf\n\u001B[0;32m--> 265\u001B[0m \u001B[43mparam\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43madd_\u001B[49m\u001B[43m(\u001B[49m\u001B[43md_p\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43malpha\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;241;43m-\u001B[39;49m\u001B[43mlr\u001B[49m\u001B[43m)\u001B[49m\n",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "source": [
    "NUM_STEPS = 40000\n",
    "BATCH_SIZE = 32\n",
    "EVAL_STEPS = 50\n",
    "X_SIZE = 1000\n",
    "OBS_SIZE = 10\n",
    "seed(22)\n",
    "network = Network(X_SIZE*(OBS_SIZE+1),OBS_SIZE)\n",
    "bst_loss = 1000.\n",
    "optim = torch.optim.SGD(network.parameters(),lr=0.1)\n",
    "loss_lst = []\n",
    "for i in range(NUM_STEPS):\n",
    "    obs_batch = torch.zeros(BATCH_SIZE,X_SIZE*(OBS_SIZE+1))\n",
    "    theta_batch = torch.zeros(BATCH_SIZE,OBS_SIZE)\n",
    "    for j in range(BATCH_SIZE):\n",
    "        x = torch.randn(X_SIZE,OBS_SIZE)\n",
    "        y = torch.randn(X_SIZE)\n",
    "        obs = torch.cat([x,y.unsqueeze(1)],dim=1)\n",
    "        obs_batch[j] = obs.flatten()\n",
    "        theta = torch.inverse(x.T@x + (1e-5)*torch.eye(OBS_SIZE))@x.T@y\n",
    "        theta_batch[j] = theta\n",
    "    loss = train_one_step(network,optim,obs_batch,theta_batch)\n",
    "    loss_lst.append(loss)\n",
    "    if i%100 == 0:\n",
    "        losses = []\n",
    "        for k in range(EVAL_STEPS):\n",
    "            x = torch.randn(X_SIZE,OBS_SIZE)\n",
    "            y = torch.randn(X_SIZE)\n",
    "            obs = torch.cat([x,y.unsqueeze(1)],dim=1)\n",
    "            theta = torch.inverse(x.T@x + (1e-5)*torch.eye(OBS_SIZE))@x.T@y\n",
    "            losses.append(eval_one_step(network,obs.flatten(),theta))\n",
    "        losses = np.mean(losses)\n",
    "        print(\"\\r| Loss at epoch {:5d} is {:8.5f} Best Loss {:7.5f} |\".format(i,losses,bst_loss,losses<bst_loss))\n",
    "        if losses < bst_loss:\n",
    "            with open(\"./models/optim.pkl\",\"wb\") as f:\n",
    "                cloudpickle.dump(network,f)\n",
    "            bst_loss = losses\n",
    "print(\"Mean loss is\",np.mean(loss_lst[-10:]))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-09-22T07:12:19.350263Z",
     "start_time": "2023-09-22T07:10:23.702655Z"
    }
   },
   "id": "cb68a5dae91402d0"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12,5))\n",
    "plt.plot(range(NUM_STEPS),loss_lst)\n",
    "plt.xlabel(\"Step\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.grid()\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "8b7e12bf4d2266f6"
  },
  {
   "cell_type": "code",
   "execution_count": 318,
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[318], line 11\u001B[0m\n\u001B[1;32m      9\u001B[0m theta2 \u001B[38;5;241m=\u001B[39m network(obs\u001B[38;5;241m.\u001B[39mflatten())\n\u001B[1;32m     10\u001B[0m tst \u001B[38;5;241m=\u001B[39m \u001B[38;5;241m10\u001B[39m\u001B[38;5;241m*\u001B[39mtorch\u001B[38;5;241m.\u001B[39mrandn(OBS_SIZE,\u001B[38;5;241m1\u001B[39m)\u001B[38;5;241m+\u001B[39m\u001B[38;5;241m100\u001B[39m\n\u001B[0;32m---> 11\u001B[0m \u001B[38;5;28mprint\u001B[39m(tst\u001B[38;5;241m.\u001B[39mT\u001B[38;5;129m@theta\u001B[39m,\u001B[38;5;124m\"\u001B[39m\u001B[38;5;130;01m\\n\u001B[39;00m\u001B[38;5;124m\"\u001B[39m,tst\u001B[38;5;241m.\u001B[39mT\u001B[38;5;129m@theta2\u001B[39m)\n",
      "File \u001B[0;32m_pydevd_bundle/pydevd_cython_darwin_311_64.pyx:1179\u001B[0m, in \u001B[0;36m_pydevd_bundle.pydevd_cython_darwin_311_64.SafeCallWrapper.__call__\u001B[0;34m()\u001B[0m\n",
      "File \u001B[0;32m_pydevd_bundle/pydevd_cython_darwin_311_64.pyx:620\u001B[0m, in \u001B[0;36m_pydevd_bundle.pydevd_cython_darwin_311_64.PyDBFrame.trace_dispatch\u001B[0;34m()\u001B[0m\n",
      "File \u001B[0;32m_pydevd_bundle/pydevd_cython_darwin_311_64.pyx:929\u001B[0m, in \u001B[0;36m_pydevd_bundle.pydevd_cython_darwin_311_64.PyDBFrame.trace_dispatch\u001B[0;34m()\u001B[0m\n",
      "File \u001B[0;32m_pydevd_bundle/pydevd_cython_darwin_311_64.pyx:920\u001B[0m, in \u001B[0;36m_pydevd_bundle.pydevd_cython_darwin_311_64.PyDBFrame.trace_dispatch\u001B[0;34m()\u001B[0m\n",
      "File \u001B[0;32m_pydevd_bundle/pydevd_cython_darwin_311_64.pyx:317\u001B[0m, in \u001B[0;36m_pydevd_bundle.pydevd_cython_darwin_311_64.PyDBFrame.do_wait_suspend\u001B[0;34m()\u001B[0m\n",
      "File \u001B[0;32m/Applications/PyCharm.app/Contents/plugins/python/helpers/pydev/pydevd.py:1160\u001B[0m, in \u001B[0;36mPyDB.do_wait_suspend\u001B[0;34m(self, thread, frame, event, arg, send_suspend_message, is_unhandled_exception)\u001B[0m\n\u001B[1;32m   1157\u001B[0m         from_this_thread\u001B[38;5;241m.\u001B[39mappend(frame_id)\n\u001B[1;32m   1159\u001B[0m \u001B[38;5;28;01mwith\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_threads_suspended_single_notification\u001B[38;5;241m.\u001B[39mnotify_thread_suspended(thread_id, stop_reason):\n\u001B[0;32m-> 1160\u001B[0m     \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_do_wait_suspend\u001B[49m\u001B[43m(\u001B[49m\u001B[43mthread\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mframe\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mevent\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43marg\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43msuspend_type\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mfrom_this_thread\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m/Applications/PyCharm.app/Contents/plugins/python/helpers/pydev/pydevd.py:1175\u001B[0m, in \u001B[0;36mPyDB._do_wait_suspend\u001B[0;34m(self, thread, frame, event, arg, suspend_type, from_this_thread)\u001B[0m\n\u001B[1;32m   1172\u001B[0m             \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_call_mpl_hook()\n\u001B[1;32m   1174\u001B[0m         \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mprocess_internal_commands()\n\u001B[0;32m-> 1175\u001B[0m         time\u001B[38;5;241m.\u001B[39msleep(\u001B[38;5;241m0.01\u001B[39m)\n\u001B[1;32m   1177\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mcancel_async_evaluation(get_current_thread_id(thread), \u001B[38;5;28mstr\u001B[39m(\u001B[38;5;28mid\u001B[39m(frame)))\n\u001B[1;32m   1179\u001B[0m \u001B[38;5;66;03m# process any stepping instructions\u001B[39;00m\n",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "source": [
    "with open(\"./models/optim.pkl\",\"rb\") as f:\n",
    "    network = cloudpickle.load(f)\n",
    "network.eval()\n",
    "with torch.no_grad():\n",
    "    x = torch.randn(X_SIZE,OBS_SIZE)\n",
    "    y = torch.randn(X_SIZE)\n",
    "    obs = torch.cat([x,y.unsqueeze(1)],dim=1)\n",
    "    theta = torch.inverse(x.T@x + (1e-5)*torch.eye(OBS_SIZE))@x.T@y\n",
    "    theta2 = network(obs.flatten())\n",
    "    tst = 10*torch.randn(OBS_SIZE,1)+100\n",
    "    print(tst.T@theta,\"\\n\",tst.T@theta2)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-09-22T07:13:25.947098Z",
     "start_time": "2023-09-22T07:12:54.000475Z"
    }
   },
   "id": "b9b41ca4c4856cdd"
  },
  {
   "cell_type": "markdown",
   "source": [
    "<h1> MLE of a gaussian </h1>"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "dbc9a7f6b5065263"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "NUM_STEPS = 20000\n",
    "BATCH_SIZE = 32\n",
    "MULTIPLIER = 10\n",
    "OBS_SIZE = 3\n",
    "seed(22)\n",
    "network = Network(3,1)\n",
    "optim = torch.optim.SGD(network.parameters(),lr=5e-4)\n",
    "loss_lst = []\n",
    "for i in tqdm(range(NUM_STEPS)):\n",
    "    loc = MULTIPLIER*torch.randn((BATCH_SIZE,)).unsqueeze(1).repeat(1,OBS_SIZE)\n",
    "    scale = MULTIPLIER*torch.randn((BATCH_SIZE,)).unsqueeze(1).repeat(1,OBS_SIZE)\n",
    "    obs = scale*torch.randn((BATCH_SIZE,3)) + loc\n",
    "    y = torch.mean(obs,dim=-1)\n",
    "    loss = train_one_step(network,optim,obs,y.unsqueeze(1))\n",
    "    loss_lst.append(loss)\n",
    "print(\"Mean loss is\",np.mean(loss_lst[-10:]))"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "104274ba10aebef8"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12,5))\n",
    "plt.plot(range(NUM_STEPS),loss_lst)\n",
    "plt.xlabel(\"Step\")\n",
    "plt.ylim(0,2)\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.grid()"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "772f063f0aeabc74"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "with open(\"./models/optim.pkl\",\"rb\") as f:\n",
    "    network = cloudpickle.load(f)\n",
    "network.eval()\n",
    "x = torch.mean(torch.tensor([200,300,150],dtype=torch.float))\n",
    "torch.allclose(network(torch.tensor([200,300,150],dtype=torch.float)),x,atol=1)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "81968cb8f166f134"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
